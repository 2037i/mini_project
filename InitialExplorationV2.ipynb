{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d011ce6b-9adf-4106-b18c-1c715f094a36",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "We will be doing the following in this section\n",
    "\n",
    "## Step 0: Getting started  \n",
    "- Import libraries  \n",
    "- Import dataset  \n",
    "\n",
    "## Step 1: Data visualisation  \n",
    "- Exploring Scope  \n",
    "- Choosing variables  \n",
    "- Visualizing individual variables  \n",
    "- Visualizing variable pairs  \n",
    "- Visualizing as a whole\n",
    "  \n",
    "## Step 2: Data analysis\n",
    "- Correlation coeficients\n",
    "- Reverse-engineering rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f479c8f-9422-4fcc-b985-e2ddd6f5c111",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 0: Getting Started\n",
    "\n",
    "Let us begin by importing the essential Python Libraries.\n",
    "\n",
    "> NumPy : Library for Numeric Computations in Python  \n",
    "> Pandas : Library for Data Acquisition and Preparation  \n",
    "> Matplotlib : Low-level library for Data Visualization  \n",
    "> Seaborn : Higher-level library for Data Visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e85ae-679d-49ae-8e67-7fb1fe6455fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c73b81-4b35-4c06-8c83-679d07c8bdee",
   "metadata": {},
   "source": [
    "### Import the Dataset (UserList)\n",
    "\n",
    "The dataset is in CSV format; hence we use the read_csv function from Pandas.  \n",
    "Immediately after importing, take a quick look at the data using the head function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888f00-e299-4100-9cdf-d25eb28fa306",
   "metadata": {},
   "outputs": [],
   "source": [
    "userlist = pd.read_csv('DataSets/Cleaned data/outV1.csv')\n",
    "userlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a7e69-6763-42dc-bfec-1f7ebb1bdead",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 1.1: Exploring scope\n",
    "\n",
    "We see that some columns are categorical, while some are numerical.  \n",
    "Let us figure out what outputs are in the categorical columns, and what range of values there are in the numerical ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb83ed19-6156-4973-86f7-6b00d825b0f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Printing out possible values of categorical variables\n",
    "\n",
    "We are interested in finding out how many types of values there are for the following columns\n",
    "1. Type\n",
    "2. Source\n",
    "3. Status\n",
    "4. Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66416e34-6906-4e1f-8eec-f3670f67e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the Type column\n",
    "type_unique_values = userlist['type'].unique()\n",
    "\n",
    "# Print the unique values for Type\n",
    "print(\"Unique values for Type:\")\n",
    "for value in type_unique_values:\n",
    "    print(value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Source column\n",
    "source_unique_values = userlist['source'].unique()\n",
    "\n",
    "# Print the unique values for Source\n",
    "print(\"Unique values for source:\")\n",
    "for value in source_unique_values:\n",
    "    print(value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Status column\n",
    "status_unique_values = userlist['status'].unique()\n",
    "\n",
    "# Print the unique values for Status\n",
    "print(\"Unique values for status:\")\n",
    "for value in status_unique_values:\n",
    "    print(value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Rating column\n",
    "rating_unique_values = userlist['rating'].unique()\n",
    "\n",
    "# Print the unique values for Rating\n",
    "print(\"Unique values for rating:\")\n",
    "for value in rating_unique_values:\n",
    "    print(value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Studio column\n",
    "studio_unique_values = userlist['studio'].unique()\n",
    "\n",
    "# Print the unique values for Studio\n",
    "print(\"Unique values for studio:\")\n",
    "for value in studio_unique_values:\n",
    "    print(value)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98ca04-d973-443b-be72-f128f6c96dbb",
   "metadata": {},
   "source": [
    "### Printing out range of values for numerical variables\n",
    "\n",
    "We are interested in finding out the minimum and maximum values for the following columns\n",
    "1. Episodes\n",
    "2. Duration\n",
    "3. Score\n",
    "4. Score_by\n",
    "5. Rank\n",
    "6. Popularity\n",
    "7. Members\n",
    "8. Favourites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8f753-74e3-4d66-ab86-c035bf5595d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the Episodes column\n",
    "episode_minimum_value = userlist['episodes'].min()\n",
    "episode_maximum_value = userlist['episodes'].max()\n",
    "\n",
    "print(\"Minimum value in for episode:\", episode_minimum_value)\n",
    "print(\"Maximum value in for episode:\", episode_maximum_value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Duration column\n",
    "duration_minimum_value = userlist['duration'].min()\n",
    "duration_maximum_value = userlist['duration'].max()\n",
    "\n",
    "print(\"Minimum value in for duration:\", duration_minimum_value)\n",
    "print(\"Maximum value in for duration:\", duration_maximum_value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Score column\n",
    "score_minimum_value = userlist['score'].min()\n",
    "score_maximum_value = userlist['score'].max()\n",
    "\n",
    "print(\"Minimum value in for score:\", score_minimum_value)\n",
    "print(\"Maximum value in for score:\", score_maximum_value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Rank column\n",
    "rank_minimum_value = userlist['rank'].min()\n",
    "rank_maximum_value = userlist['rank'].max()\n",
    "\n",
    "print(\"Minimum value in for rank:\", rank_minimum_value)\n",
    "print(\"Maximum value in for rank:\", rank_maximum_value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Popularity column\n",
    "popularity_minimum_value = userlist['popularity'].min()\n",
    "popularity_maximum_value = userlist['popularity'].max()\n",
    "\n",
    "print(\"Minimum value in for popularity:\", popularity_minimum_value)\n",
    "print(\"Maximum value in for popularity:\", popularity_maximum_value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Members column\n",
    "member_minimum_value = userlist['members'].min()\n",
    "member_maximum_value = userlist['members'].max()\n",
    "\n",
    "print(\"Minimum value in for member:\", member_minimum_value)\n",
    "print(\"Maximum value in for member:\", member_maximum_value)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtering the Favourites column\n",
    "favourite_minimum_value = userlist['favorites'].min()\n",
    "favourite_maximum_value = userlist['favorites'].max()\n",
    "\n",
    "print(\"Minimum value in for favourite:\", favourite_minimum_value)\n",
    "print(\"Maximum value in for favourite:\", favourite_maximum_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b525eea-831c-4af0-9310-c221770c17a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 1.2: Choosing Initial Variables\n",
    "\n",
    "We have decided to pick 5 variables to explore, and this section breaks down what they mean and how they are calculated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830faa31-ce9f-4894-b644-586dd191fe00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Score\n",
    "\n",
    "Score is a weighted average of the rating that users give to a particular anime  \n",
    "It is calculated using the following formula:  \n",
    "\n",
    "(v/(v+m)) * S + (m/v+m) * C  \n",
    "\n",
    "Where\n",
    "> v = Number of users giving a score  \n",
    "> m = Minimum number of scored users required to get a calculated score  \n",
    "> S = Average score  \n",
    "> C = Mean score across the entire datase \n",
    "\n",
    "We can see that S and C are essentially unweighted averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e79b0d-4b5b-48d1-a714-36fc704fa8a1",
   "metadata": {},
   "source": [
    "### Rank\n",
    "\n",
    "It is not immediately clear how rank is calculated, perhaps we can run a regression operation to reverse engineer the formula..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d841639-8b3f-4266-b711-554dd0a88c11",
   "metadata": {},
   "source": [
    "### Popularity\n",
    "\n",
    "This is the number of viewers that watched a particular anime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e0984-237f-4ace-b759-4b4d962e280a",
   "metadata": {},
   "source": [
    "### Members\n",
    "\n",
    "This is the number of people who added a particular anime to their list  \n",
    "The list is for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b2f513-d2d3-4413-b448-5bc205586898",
   "metadata": {},
   "source": [
    "### Favourites\n",
    "\n",
    "This is the number of people who favourited a particular anime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c412d7a2-928a-4c6d-8008-9e6eef1b8919",
   "metadata": {},
   "source": [
    "## Step 1.3: Visualizing Individual Variables\n",
    "\n",
    "Let us look in more detail at each chosen variable, using visual tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d03366-7b76-4899-b43b-49e2f64e870d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fca114bc-2efa-414b-915f-28380a85b26e",
   "metadata": {},
   "source": [
    "## Step 1.4: Looking at chosen variables in pairs\n",
    "\n",
    "Now that we know what the variables entail, let us compare them against one another"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838fd61-1b40-40b5-b7e8-bc1a6bb62337",
   "metadata": {},
   "source": [
    "## Step 1.5: Comparing all chosen variables\n",
    "\n",
    "Here we utilize a pair-plot to get the big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192833a-0fcb-4b6d-a659-f43e6d42e9e2",
   "metadata": {},
   "source": [
    "## Step 2.1: Correlation Coefficients\n",
    "\n",
    "We look at correlation coefficients - specifically against Rank, in order to clue us into which variables to consider for reverse engineering its formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f054781-cae4-4f82-aae3-ea2d5f73264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating correlation coefficient between rank and score \n",
    "rank_vs_score_correlation_coefficient = userlist['rank'].corr(userlist['score'])\n",
    "print(f\"Correlation Coefficient between rank and score: {rank_vs_score_correlation_coefficient}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Calculating correlation coefficient between rank and popularity \n",
    "rank_vs_popularity_correlation_coefficient = userlist['rank'].corr(userlist['popularity'])\n",
    "print(f\"Correlation Coefficient between rank and popularity: {rank_vs_popularity_correlation_coefficient}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Calculating correlation coefficient between rank and members\n",
    "rank_vs_members_correlation_coefficient = userlist['rank'].corr(userlist['members'])\n",
    "print(f\"Correlation Coefficient between rank and members: {rank_vs_members_correlation_coefficient}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Calculating correlation coefficient between rank and favourites\n",
    "rank_vs_favorites_correlation_coefficient = userlist['rank'].corr(userlist['favorites'])\n",
    "print(f\"Correlation Coefficient between rank and favorites: {rank_vs_favorites_correlation_coefficient}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ecf71-a246-4f75-a739-4a45c95d4763",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "Remember that to intepret the values:  \n",
    "> -1 indicates perfect negative correlation  \n",
    "> 0 indicates no correlation  \n",
    "> 1 indicates perfect positive correlation\n",
    "\n",
    "With that in mind, these are the coefficients (rounded off to 5 d.p.):\n",
    "* Rank and score: -0.66519\n",
    "* Rank and popularity: 0.70756\n",
    "* Rank and members: -0.38977\n",
    "* Rank and favorites: -0.18767\n",
    "\n",
    "From the results above, we can easily eliminate favourites as a variable, given how close its value is to 0  \n",
    "Members is also up for consideration for elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bec5a-d135-4870-8339-5106b942d002",
   "metadata": {},
   "source": [
    "## Step 2.2: Linear Regression\n",
    "\n",
    "Let's try the simplest form of modelling to predict Rank as a start!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bca063-672b-41c9-87d0-d1b270bd5b29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Splitting the data\n",
    "\n",
    "We must first split the data into train and test sets\n",
    "Take note that a seed value of 42 was chosen here for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f410eef-fe70-4c52-81f4-ea5d133ea6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing) with a seed of 42\n",
    "Predictor_3var_train, Predictor_3var_test, Response_train, Response_test = train_test_split(Predictor_3var, Response, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb9b78e-cda1-439e-8496-6b473e42a5e0",
   "metadata": {},
   "source": [
    "### 3-Variable Model\n",
    "\n",
    "Since we aren't sure if Members should be included as a variable to predict Rank, let us include it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd446a7b-33b0-4d90-b62f-f1d416f4ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor_3var contains the features (score, popularity, members) \n",
    "# Response contains the target variable (rank)\n",
    "Predictor_3var = userlist[['score', 'popularity', 'members']]\n",
    "Response = userlist['rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6983ab-1040-450e-8199-2e3f78143232",
   "metadata": {},
   "source": [
    "We create a linear regression model and train it using the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7ef89-9cb5-4d29-9a9f-b718b275b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create and train the linear regression model\n",
    "linear_reg_model_3var = LinearRegression()\n",
    "linear_reg_model_3var.fit(Predictor_3var_train, Response_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47512b-a273-4962-801e-835b207188ee",
   "metadata": {},
   "source": [
    "After training, we use the model to predict rank on the test set  \n",
    "We then plot the resulting predictions to check if anything looks unusual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4995b-14b5-43ab-a217-03bfd2e96a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Rank for the test set\n",
    "Rank_pred_linear_reg_3var = linear_reg_model_3var.predict(Predictor_3var_test)\n",
    "\n",
    "# Plot the Predictions\n",
    "f = plt.figure(figsize=(16, 8))\n",
    "plt.scatter(Response_test, Rank_pred_linear_reg_3var, color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734e3f4-e3a6-4a74-b27a-e7b35a0cde09",
   "metadata": {},
   "source": [
    "To get a better evaluation of how effective the model is, we use the following metrics:\n",
    "1. Mean Squared Error (MSE): The average of the squared differences between the predicted values and the actual values\n",
    "2. Root Mean Squared Error (RMSE): A measure of the average magnitude of the errors in the predicted values\n",
    "3. Mean Absolute Error (MAE): The average of the absolute differences between the predicted values and the actual values\n",
    "4. Coefficient of Deterimination (R^2): The proportion of the variance in the target variable that is explained by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395eea8-f32a-4e62-af36-13cbd3a72998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_3var = mean_squared_error(Response_test, Rank_pred_linear_reg_3var)\n",
    "print(f\"Mean Squared Error: {mse_3var}\")\n",
    "\n",
    "# Calculaing root mean squared error\n",
    "rmse_3var = mean_squared_error(Response_test, Rank_pred_linear_reg_3var, squared = False)\n",
    "print(f\"Root Mean Squared Error: {rmse_3var}\")\n",
    "\n",
    "# Calculating mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_3var = mean_absolute_error(Response_test, Rank_pred_linear_reg_3var)\n",
    "print(f\"Mean Absolute Error: {mae_3var}\")\n",
    "\n",
    "# Calculating coefficient of determination\n",
    "from sklearn.metrics import r2_score\n",
    "r2_3var = r2_score(Response_test, Rank_pred_linear_reg_3var)\n",
    "print(f\"R-squared Score: {r2_3var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc1c32-33e9-4c50-8878-6557b908bd15",
   "metadata": {},
   "source": [
    "### 2-Variable Model\n",
    "\n",
    "Let us also try linear regression without members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeadeb5-34cf-4906-b203-18e07a4712f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor contains the features (score and popularity) \n",
    "# Response contains the target variable (rank)\n",
    "Predictor_2var = userlist[['score', 'popularity']]\n",
    "Response = userlist['rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80423db-f0fb-4900-b032-8a7b47a4eac5",
   "metadata": {},
   "source": [
    "After splitting the data, we create a linear regression model and train it using the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f3d61-9fff-4f64-9d90-16640ea95fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create and train the linear regression model\n",
    "linear_reg_model_2var = LinearRegression()\n",
    "linear_reg_model_2var.fit(Predictor_2var_train, Response_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c24ddb-6dd6-4865-9f8c-92a045510529",
   "metadata": {},
   "outputs": [],
   "source": [
    "After training, we use the model to predict rank on the test set  \n",
    "We then plot the resulting predictions to check if anything looks unusual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a969e5-a1a2-493e-9f8c-74db90d2babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Rank for the test set\n",
    "Rank_pred_linear_reg_2var = linear_reg_model_2var.predict(Predictor_2var_test)\n",
    "\n",
    "# Plot the Predictions\n",
    "f = plt.figure(figsize=(16, 8))\n",
    "plt.scatter(Response_test, Rank_pred_linear_reg_2var, color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a11f8-805c-4a75-a132-9bce403741d1",
   "metadata": {},
   "source": [
    "To get a better evaluation of how effective the model is, we use the following metrics:\n",
    "1. Mean Squared Error (MSE): The average of the squared differences between the predicted values and the actual values\n",
    "2. Root Mean Squared Error (RMSE): A measure of the average magnitude of the errors in the predicted values\n",
    "3. Mean Absolute Error (MAE): The average of the absolute differences between the predicted values and the actual values\n",
    "4. Coefficient of Deterimination (R^2): The proportion of the variance in the target variable that is explained by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21ac86-b2fc-422b-b4a6-d9390ba37744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_2var = mean_squared_error(Response_test, Rank_pred_linear_reg_2var)\n",
    "print(f\"Mean Squared Error: {mse_2var}\")\n",
    "\n",
    "# Calculaing root mean squared error\n",
    "rmse_2var = mean_squared_error(Response_test, Rank_pred_linear_reg_2var, squared = False)\n",
    "print(f\"Root Mean Squared Error: {rmse_2var}\")\n",
    "\n",
    "# Calculating mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_2var = mean_absolute_error(Response_test, Rank_pred_linear_reg_2var)\n",
    "print(f\"Mean Absolute Error: {mae_2var}\")\n",
    "\n",
    "# Calculating coefficient of determination\n",
    "from sklearn.metrics import r2_score\n",
    "r2_2var = r2_score(Response_test, Rank_pred_linear_reg_2var)\n",
    "print(f\"R-squared Score: {r2_2var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc73ad0-0993-416a-a618-85f9a25e4546",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "Let's compare the 4 metrics from both models to see which one is more accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c722e13c-f008-4bf1-8a36-5fb0f4c98586",
   "metadata": {},
   "source": [
    "Remember that to evaluate these metrics\n",
    "> A lower MSE indicates better performance (0 lowest)\n",
    "> A lower RMSE indicates better performance (0 lowest)\n",
    "> A lower MAE indicates better performance (0 lowest)\n",
    "> A higher R^2 indicates better performance (1 highest)\n",
    "\n",
    "Here are the results for the 3-var model (rounded off to 5 d.p.):\n",
    "* Mean Squared Error: 6269914.25204\n",
    "* Root Mean Squared Error: 2503.97968\n",
    "* Mean Absolute Error: 1828.76560\n",
    "* R-Squared Score: 0.62505\n",
    "\n",
    "And here are the results for the 2-var model (rounded off to 5 d.p.):\n",
    "* Mean Squared Error: 6307853.47160\n",
    "* Root Mean Squared Error: 2511.54404\n",
    "* Mean Absolute Error: 1827.69689\n",
    "* R-Squared Score: 0.62278\n",
    "\n",
    "We can see that they are extremely close, with R^2 scores only differing by around 0.0022. Even though the MSE and RMSE go up slightly, the MAE actually falls slighly too   \n",
    "\n",
    "Thus, we conclude that Members is indeed not a very helpful metric for determining Rank, so it can be safely removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf671fcd-b85e-40f4-9d39-4ea2be1d8b9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Retrieving the formula\n",
    "\n",
    "Now that we have our chosen model, let us retrieve the exact coefficients and intercepts that were used to generate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da769ab2-c38a-422e-9721-85060dd12769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the coefficients and intercept\n",
    "coefficients_2var = linear_reg_model_2var.coef_\n",
    "intercept_2var = linear_reg_model_2var.intercept_\n",
    "\n",
    "# Construct the formula\n",
    "formula = f\"Rank = {intercept_2var:.2f} + \"\n",
    "for i, coef in enumerate(coefficients_2var):\n",
    "    formula += f\"({coef:.2f} * Predictor_{i+1}) + \"\n",
    "\n",
    "# Remove the trailing '+' and whitespace\n",
    "formula = formula[:-3]\n",
    "\n",
    "print(\"Formula:\", formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6388c94-d106-4767-86f0-305ffde05a0a",
   "metadata": {},
   "source": [
    "We can this see that:  \n",
    "Rank = 10629.83 + (-1127.91 * Score) + (0.48 * Popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa82a3-6bdc-438c-8eed-da9f0940d355",
   "metadata": {},
   "source": [
    "## Step 2.3: Polynomial Regression\n",
    "\n",
    "A polynomial regression is able to capture more complex patterns in the data. Maybe that will help us predict Rank better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63db08d-586f-48fd-9736-605b45521751",
   "metadata": {},
   "source": [
    "### Degree-2 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590fc61-ce3b-400c-9537-78b5ee184a65",
   "metadata": {},
   "source": [
    "We will be re-using the previous train and test sets, Predictor_2var and Response, except they will now be converted into polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e518f-96d0-419a-a791-94a7dd94e35f",
   "metadata": {},
   "source": [
    "### Degree-3 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08001fad-c889-4ca9-9693-399562682144",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725fc46d-ae88-48b1-a18a-584d2a35f56b",
   "metadata": {},
   "source": [
    "### Retrieving the formula"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
